<!DOCTYPE html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="viewport" content="width=device-width">
  <title>What is a good list of inconsistencies in physics that forced us to develop much more mathematically advanced theories to explain the inconsistencies?</title>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="load-mathjax.js" defer></script>
	<style type="text/css">
		a:link {
		  	text-decoration:none;
		}
		.reply3 {
			font-family: Arial, Helvetica, Geneva, Sans-serif, sans-serif; 
			/*padding: 4px;
			padding-left: 15px;*/
			/*color: #789922;*/
			color:#e00707;
		}
		p, ul, ol, li, h4 {
			font-family: Arial, Helvetica, Geneva, Sans-serif, sans-serif; 
		}
	</style>
</head>

<!-- Write your comments here -->

<body>

	<div>
		<p>Here are the most famous historical paradoxes in field theory:</p>
		<ol>
		<li>
		<p><b>the Klein paradox:</b> When you scatter a Dirac equation electron off a barrier which is high enough, the reflection and transmission probabilities add up to more than one! This paradox and it's resolution can be explained simply today as follows: if you look at the positive frequency solutions to the Klein Gordon equation, these travel faster than light, they can't be restricted to be slower than light. This means that you need antiparticle creation if you have a potential, because anything that can make something go faster than light can make it go back in time too. The greater-than-1 probabilities in the Klein paradox are due to unaccounted for pair-creation in the step-potential. This was also the historical resolution--- going to a field theory for the Dirac equation.</p>
		</li>
		<li>
		<p><b>The Dirac equation quantizes wrong:</b> If you use commutators to quantize the Dirac field, you get an energy which is negative infinity. This was resolved by the Jordan/Fermi resolution--- you use anticommutation relations instead of commutation relations for the Fermionic equation. This was equivalent to the exclusion principle (antisymmetric wavefunctions) and the filled Dirac sea proposed by Dirac, which was a slightly more intuitive picture, but less formally mathematically elegant. The general result is the spin/statistics theorem of Fierz, Pauli. Later Schwinger gave a nice demonstration that explained why it is true using intuitive rotations in imaginary time (Wikipedia explains this).</p>
		</li>
		<li>
		<p><b>The infinities of higher order perturbations:</b> when you calculate the probability amplitude contribution of any process involving an electron emitting and later absorbing the same photon, you get an infinite result, coming from very short times. This was resolved by renormalization, by Stueckelberg, Bethe, Schwinger, Feynman, Tomonaga and Dyson.</p>
		</li>
		<li>
		<p><b>Landau's paradox for critical exponents:</b> Lev Landau, using a simple version of what later came to be called "catastrophe theory", predicted that all critical exponents should be simple rational numbers, and gave specific values for what they should be. So he predicted that the magnetization in a magnet cooled below it's Curie point (when it becomes spontaneously magnetized) should, once you get past the critical point, always go up from zero as the square root of the temperature change from the critical point. But it wasn't true experimentally, and it wasn't true in the exactly solvable Ising model. So there was something strange going on. This inconsistency led to the development of modern renormalization.</p>
		</li>
		<li>
		<p><b>Mass wrecks renormalization (except in QED):</b> If you introduce a mass into quantum electrodynamics, you break a principle of gauge invariance, so you think that renormalizability will fail (because you will introduce all sorts of new terms), but it doesn't fail. This was noted by Feynman and Schwinger, and explained by Stueckelberg. The idea that mass doesn't change renormalization properties of theories of this sort was widely believed after that, but it was explicitly disproved by 't Hooft, who showed that the mass does wreck renormalizability in theories where photons self-interact with other photons, the nonabelian gauge theories. This led to the development of the classic techniques of Veltman and 't Hooft, including dimensional regularization and minimal subtraction, which automated calculations in standard field theory.</p>
		</li>
		<li>
		<p><b>Anomaly I:</b> The decay of the neutral pion/Missing eta-prime: The neutral pion decays into two photons, but it isn't allowed to decay into two photons by the Sutherland-Veltman theorem. The reason is because there was the principle that the axial vector current is conserved (we would say today that the quarks keep their helicity, in those days it wasn't said in terms of quarks). This theorem was contradicted by an explicit calculation, and this means it's not a theorem, but the algebraic manipulations in the proof looked correct. The resolution to this paradox is that there is an anomaly in the axial current, that means that when you differentiate the axial current, you get an extra term, and this extra term comes from renormalization. For the missing eta-prime: There are three pions, but there naively should be four, because the lightest quarks have that many ways to rotate into each other. This was resolved by the t'Hooft anomaly, he showed that the fourth chiral current was violated by the strong interactions. Later Venziano and Witten showed how much heavier the fourth particle should be than the other pions, this is the eta-prime.</p>
		</li>
		<li>
		<p><b>Anomaly II:</b> The missing charm quark: Glashow Iliapulous and Miaini showed that the standard model was inconsistent unless there was a charm quark. This prediction was verified in November 1974, when two groups discovered the charm quark mesons.</p>
		</li>
		<li>
		<p><b>Anomaly III:</b> Trace anomaly: This was the observation that the scale invariance was busted, which led to the Callan Symanzik relation.</p>
		</li>
		<li>
		<p><b>Hawking radiation:</b> This was the observation that quantum field theory on a black hole background will produce particles in thermal equilibrium, even though the background looks static, and there's a theorem that static backgrounds don't make radiation. The theorem doesn't work because the background is only fake-static, the horizon is a place where time changes character from space, and you can't really call it static--- the space-time is peeling apart constantly there. This result was surprising.</p>
		</li>
		<li>
		<p><b>Weird renormalizability of SUGRA:</b> people expected N=8 supergravity to fail to be renormalizable at a certain order, but explicit calculations show that it keeps being finite well past the point it should start to diverge. This is not resolved today, and it a major focus of research, associated with Lance Dixon.</p>
		</li>
		</ol>
		<p>I tried to stick to out and out paradoxes in field theory. There are a ton I left out--- like the SU(6) theorems--- that you can't mix spacetime and internal symmetries, this was the O'Raifertaigh Coleman Mandula result, and there's lots more. Field theory was full of paradoxes for decades, although they are sorted out now in physics, as mathematics it's a different story.</p>
	</div>



<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>
</body>

</html>